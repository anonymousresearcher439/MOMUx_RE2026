## Intent Awareness and Behavior Understanding Requirements

This section captures requirements derived from SIGACTs that reveal challenges in understanding the intentions and expected behaviors of autonomous systems during operations. These observations highlight situations where operators could observe what sUAS were doing but lacked sufficient context to understand why those actions were occurring, leading to confusion, misinterpretation of valid behaviors as anomalies, and reduced confidence in supervisory decision-making.

The requirements focus on supporting operators in forming accurate mental models of system behavior by making planned behaviors and their context visible, particularly when autonomous decisions or transitions occur. The goal is to enable operators to interpret system actions correctly, anticipate behavior, and maintain trust in the autonomy while reducing uncertainty during supervision.

The following SIGACTs reflect a progression from challenges in understanding autonomous behavior to difficulties in assessing correctness and determining appropriate intervention.

| ID | SIGACT | Root Problem | Main Requirement | Derived | NFR Example |
|----|--------|-------------|------------------|---------|-------------|
| S11 | TO suffers from loss of sUAS intentionality projection, preventing understanding of movements and leading to confusion about whether sUAS are on course | The Tactical Operator had visibility into broad operational boundaries but lacked insight into the planned behaviors of individual sUAS. Without information about expected system actions, the operator could not distinguish between valid autonomous maneuvers and anomalies, leading to correct behavior being interpreted as erratic or surprising. | The Tactical Operator interfaces shall provide information about the planned behaviors of sUAS during operations. | The system shall provide information that supports operator understanding of why each sUAS is behaving as observed. | Operators shall be able to explain the current behavior of a specified sUAS in at least 98% of trials. |
| S12, S31 | The team is unable to determine whether sUAS are following their planned trajectories, leading to uncertainty about correct operation. | Operators can observe current positions but lack support to assess whether flight paths remain aligned with planned trajectories over time, resulting in uncertainty about trajectory adherence rather than visibility. | The system shall support operators in determining whether each sUAS is adhering to its planned trajectory during operations. | The system shall report deviations between observed flight paths and planned trajectories. | An operator shall correctly determine whether a specified sUAS is following its planned trajectory in at least P% of trials. |
| S13, S31 | The team interprets normal autonomous behavior as erratic or abnormal because they do not receive clear indications of whether the flight controller or autopilot considers the behavior nominal or problematic. | Operators lack authoritative cues from the flight controller or autopilot about whether observed behavior reflects nominal, degraded, or failsafe conditions, leading them to infer abnormality from appearance alone and misclassify normal actions. | The system shall support operators in understanding whether observed sUAS behavior reflects nominal, degraded, or abnormal operating conditions. | When the flight controller or autopilot reports an abnormal, degraded, or failsafe condition affecting sUAS behavior, the system shall communicate that condition to operators during operations. | Given an abnormal, degraded, or failsafe notification, operators shall correctly state the condition, the affected sUAS, and the recommended operational implication within T seconds in at least P% of trials. 
| S14, S32 | Operators either assumed manual control for behavior later determined to be normal or hesitated to intervene due to insufficient confidence or data to confirm concerns. | Operators lack clear cues about the operational significance of alerts or unexpected behavior, leading to uncertainty in deciding whether intervention is appropriate. This uncertainty can result in both precautionary overrides and delayed intervention. | The system shall support operators in determining whether manual intervention is warranted during autonomous operations, including situations where intervention may be necessary or unnecessary. | When alerts or unexpected behaviors occur, the system shall communicate their operational significance to support operator judgment regarding whether intervention is appropriate. | Operators shall make correct intervention decisions, including both avoiding unnecessary overrides and intervening when required, in at least P% of evaluated scenarios. |
